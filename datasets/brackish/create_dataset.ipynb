{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set input and output paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "# CHANGE THESE TWO\n",
    "input_folder = r\"/home/beuss/Downloads/datasets/brackish\" # Path to the root of the brackish dataset\n",
    "output_folder = r\"/home/beuss/Downloads/datasets/brackish/out\" # Path to the root of the output (dataset) folder, use this in brackish.yaml\n",
    "\n",
    "# Optional parameters\n",
    "train_split = 0.8\n",
    "validation_split = 0.1\n",
    "test_split = 0.1\n",
    "seed = 1234567890\n",
    "\n",
    "\n",
    "#--------------------------------------------------------------\n",
    "\n",
    "input_folder = os.path.abspath(input_folder)\n",
    "output_folder = os.path.abspath(output_folder)\n",
    "\n",
    "dataset_folder = os.path.join(input_folder, \"dataset\")\n",
    "\n",
    "all_images_folder = os.path.join(output_folder, \"images\", \"all\")\n",
    "all_labels_folder = os.path.join(output_folder, \"labels\", \"all\")\n",
    "\n",
    "print(f\"Input folder: {input_folder}\")\n",
    "print(f\"Output folder: {output_folder}\")\n",
    "print(f\"All images folder: {all_images_folder}\")\n",
    "print(f\"All labels folder: {all_labels_folder}\")\n",
    "\n",
    "def execute(cmd, print_output=False):\n",
    "    try:\n",
    "        if print_output:\n",
    "            print(\"executing: \" + cmd)\n",
    "        output = subprocess.check_output(cmd,shell=True,stderr=subprocess.STDOUT)\n",
    "        if print_output:\n",
    "            print(output.decode(\"UTF-8\"))\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(\"command '{}' return with error (code {}): {}\".format(e.cmd, e.returncode, e.output))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract all the images from the videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_categories = [\"crab\", \"fish-big\", \"fish-school\", \"fish-small-shrimp\", \"jellyfish\"]\n",
    "\n",
    "print(\"Dataset folder: \" + dataset_folder)\n",
    "for category in video_categories:\n",
    "    input = os.path.join(dataset_folder, \"videos\", f\"{category}\")\n",
    "    command = f\"python frame_extractor.py --inputFolder \\\"{input}\\\" --outputFolder \\\"{all_images_folder}\\\"\"\n",
    "    execute(command, print_output = True)\n",
    "    print(\"Finished extracting frames for \" + category)\n",
    "\n",
    "print(\"Done extracting frames!\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to compile the image list to \"imagelist.txt\" and then copy all the images to a common folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute(f\"python create_image_list.py --inputFolder \\\"{all_images_folder}\\\"\")\n",
    "print(\"Created imagelist.txt\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fake annotations for images with no fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute(f\"python create_dummy_yolo_annotations.py --inputFolder \\\"{all_images_folder}\\\" --outputFolder \\\"{all_labels_folder}\\\"\", print_output=True)\n",
    "print(\"Created dummy annotations\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create real annotations for images with fish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotation_files = [\"test.csv\", \"valid.csv\", \"train.csv\"]\n",
    "for annotation_file in annotation_files:\n",
    "    annotation_csv = os.path.join(input_folder, \"annotations\", \"annotations_AAU\", annotation_file)\n",
    "    categories = os.path.join(input_folder, 'Brackish.names')\n",
    "\n",
    "    print(f\"Processing {annotation_file}...\")\n",
    "    execute(f\"python annotations_to_yolo.py --imageFolder \\\"{all_images_folder}\\\" --annotationCSV \\\"{annotation_csv}\\\" --outputPath \\\"{all_labels_folder}\\\" --categories \\\"{categories}\\\"\")\n",
    "    print(f\"Finished converting annotations for {annotation_file}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that all images have a corresponding label file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify that all images have a corresponding label file\n",
    "(_, _, image_files) = next(os.walk(all_images_folder))\n",
    "(_, _, label_files) = next(os.walk(all_labels_folder))\n",
    "\n",
    "for image_file in image_files:\n",
    "    label_file = os.path.splitext(image_file)[0] + \".txt\"\n",
    "    # Ignore inputList.txt, this is generated by frame_extractor.py\n",
    "    if label_file not in label_files and label_file != \"inputList.txt\":\n",
    "        raise Exception(f\"Missing label file for {image_file}\")\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split all training data into a training set, validation set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute(f\"python create_dataset_split.py --inputFile \\\"imagelist.txt\\\" --seed {seed} --trnSplit {train_split} --valSplit {validation_split} --tstSplit {test_split}\", print_output=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy training data into their respective folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import pathlib\n",
    "\n",
    "stages = [\"train\", \"valid\", \"test\"]\n",
    "\n",
    "for stage in stages:\n",
    "    stage_file = f\"{stage}.txt\"\n",
    "    stage_images_folder = os.path.join(output_folder, \"images\", f\"{stage}\")\n",
    "    stage_labels_folder = os.path.join(output_folder, \"labels\", f\"{stage}\")\n",
    "\n",
    "    # Create stage folders if they don't exist\n",
    "    pathlib.Path(stage_images_folder).mkdir(exist_ok=True, parents=True)\n",
    "    pathlib.Path(stage_labels_folder).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    print(f\"Copying {stage} files...\")\n",
    "    print(f\"Image folder: {stage_images_folder}\")\n",
    "    print(f\"Label folder: {stage_labels_folder}\")\n",
    "\n",
    "    with open(stage_file, \"r\") as f:\n",
    "        for line in f:\n",
    "            image_file = os.path.join(all_images_folder, line.strip())\n",
    "            filename = os.path.split(line.strip())\n",
    "            label_file = os.path.join(all_labels_folder, os.path.splitext(filename[1])[0] + \".txt\")\n",
    "\n",
    "            # Copy files to stage folders\n",
    "            shutil.copy2(image_file, stage_images_folder)\n",
    "            shutil.copy2(label_file, stage_labels_folder)\n",
    "    print(f\"Done copying '{stage}' files!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f8e5365787798d4b66b26a6428a41300114addd75b65cd304315c53a7a72bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
